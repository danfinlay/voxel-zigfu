An experiment to pupeteer a voxel person with an OpenNI/NITE-enabled depth sensor (like the Xbox Kinect).

Right now I'm wrapping my head around the kinematics to make this work right.

I was hoping to rotate an arm in place by simply finding the appropriate Z then Y rotations, but when my calculations are stacked, they will sometimes go so far as to cancel each other out.

If anyone knows this material, feel free to chip it in, in the meanwhile I plan to read the Robotics chapter of "Making Things See", which I hope/suspect will help me wrap my head around this.

A live demo, featuring the right arm active with the current problem is [here](http://danfinlay.com/projects/voxeljs/zigfu/).